{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw07_Sabine.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO7FMd8cm0Kkfem5cD5WnZx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juelha/IANNWTF/blob/sabine/hw07_Sabine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.2 Generate a Tensorflow Datset\n",
        "You can of course now go on and compute a big bunch of examples and store\n",
        "them in a huge array or dataframe or whatever you like. However, that would\n",
        "be rather inefficient - as we work with random noise input, we can compute the\n",
        "data on the fly.\n",
        "Thus, we would like you to work with generators 1 and the tensorflow\n",
        "function tf.data.Dataset.from generator().\n",
        "There are a few simple steps to take:\n",
        "\n",
        "• Write a integration task(seq len, num sapmles) generator function: This function should for num samples times 2 yield a random noise\n",
        "signal of the size seq len 3\n",
        "(sequence length, thus the number of time steps\n",
        "2\n",
        "we are considering) and a target, namely if the sum of the noise signal is\n",
        "greater or smaller than 1. 4\n",
        "You make your life easier if you do not try to handle empty dimensions!5\n",
        "\n",
        "• Write a wrapper generator my integration task(): As it is easier to\n",
        "pass a generator to the tensorflow tf.data.Dataset.from generator()\n",
        "method that does not take any arguments, write a wrapper function\n",
        "which internally iterates to integration task with a specified seq len and\n",
        "num samples and yields the function’s yield (yes sounds stupid and complicated, but it’s really easier that way).\n",
        "Choose num samples to be rather high 6\n",
        ", as you do not want to overfit and\n",
        "you may want to start with a small sequence length for easier debugging.\n",
        "In the end, you should however be able to deal with a sequence length of\n",
        "25 at least.\n",
        "\n",
        "• Create the Tensorflow Dataset: Pass on your wrapper generator to\n",
        "tf.data.Dataset.from generator(, output signature= tf.TensorSpec(shape,\n",
        "dtype).\n",
        "\n"
      ],
      "metadata": {
        "id": "uuC2yWfmZyEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.integrate as integrate\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "BCcoJlXFapmW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZSLHsA2wVBqN"
      },
      "outputs": [],
      "source": [
        "# Dataset Setup\n",
        "\n",
        "''''\n",
        "def integration_task(seq_len, num_samples): \n",
        "\n",
        "  for sample in range(num_samples):\n",
        "    f = lambda x: np.random.normal(loc=0, scale=2)\n",
        "    i = integrate.quad(f,0,seq_len)\n",
        "    print(i[0])\n",
        "\n",
        "integration_task(5, 1)\n",
        "\n",
        "'''\n",
        "seq_len = 3\n",
        "num_samples = 80000\n",
        "\n",
        "def integration_task(seq_len, num_samples): \n",
        "  for sample in range(num_samples):\n",
        "    noise_signal=np.array([])\n",
        "    for signal in range(seq_len):\n",
        "      noise_signal = np.append(noise_signal, np.random.normal(loc=0, scale=2)) # noise signal ints of length seq_len\n",
        "    target = np.array(int(np.sum(noise_signal)>0))\n",
        "    noise_signal = np.expand_dims(noise_signal,-1) \n",
        "    target = np.expand_dims(target,-1)\n",
        "    #print(noise_signal.shape, target.shape)\n",
        "    yield noise_signal, target\n",
        "\n",
        "def wrapper_generator(): \n",
        "  return integration_task(seq_len,num_samples)\n",
        "\n",
        "wrapper_generator()\n",
        "\n",
        "dataset = tf.data.Dataset.from_generator(wrapper_generator, output_signature= \n",
        "                                                                 (tf.TensorSpec(shape=(seq_len,1), dtype=tf.float32),\n",
        "                                                                  tf.TensorSpec(shape=(1), dtype=tf.float32)))\n",
        "\n",
        "#list(dataset.take(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.3 Create a Data pipeline\n",
        "Now you should have a Tensorflow Dataset object and thus should be able to\n",
        "apply all the necessary preprocessing steps to create an efficient pipeline. 7"
      ],
      "metadata": {
        "id": "xvQ1MG3MEgB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * num_samples)\n",
        "valid_size = int(0.15 * num_samples)\n",
        "\n",
        "train_ds = dataset.take(train_size)\n",
        "remaining = dataset.skip(train_size)  \n",
        "valid_ds = remaining.take(valid_size)\n",
        "test_ds = remaining.skip(valid_size)\n",
        "\n",
        "#assert dataset.shape == (80000, 3, 1)\n",
        "\n",
        "def preprocessing(tensor):\n",
        "  \"\"\" apply a preprocessing pipeline to the given dataset\n",
        "  :param tensor: data to be preprocessed\n",
        "  :return: preprocessed dataset\n",
        "  \"\"\"\n",
        "  # shuffle, batch, prefetch\n",
        "  tensor = tensor.shuffle(1000)\n",
        "  tensor = tensor.batch(32)\n",
        "  tensor = tensor.prefetch(20)\n",
        "  # return preprocessed dataset\n",
        "  return tensor\n",
        "\n",
        "train_dataset = train_ds.apply(preprocessing)\n",
        "test_dataset = test_ds.apply(preprocessing)\n",
        "\n",
        "dataset = dataset.apply(preprocessing)\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxwAxqQeEokf",
        "outputId": "29316d6f-b1f4-4cfa-8980-40abd315faba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PrefetchDataset shapes: ((None, 3, 1), (None, 1)), types: (tf.float32, tf.float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 The network\n",
        "While there are great implementations in tensorflow/keras for LSTMs, this week\n",
        "you are asked to build your own! So you are restricted from using any tensorflow/keras inbuilt of LSTM (or RNN!). You can however use Dense layers for\n",
        "the matrix multiplications.\n",
        "To do so, there are several steps you need to take:\n",
        "\n",
        "1. Implement a LSTM Cell which is called by providing the input for a\n",
        "single times step and a tuple containing (hidden state, cell state).\n",
        "\n",
        "• init (self,units): Remember again what gates an LSTM consists of and how to parametrize them. 8 Pay special attention to\n",
        "weight initialization: According to Josezefowicz et al. Setting the\n",
        "bias of the forget gate to one initially is very important for performance in training LSTMs. 9 Think about it for a moment - what\n",
        "effect would that have on the initial output values of this gate, and\n",
        "what effect will that have on the recurrent cell state? This is actually implemented in the default LSTM cell in Tensorflow - check the\n",
        "unit forget bias argument there for more information!\n",
        "3\n",
        "\n",
        "• call(self, x, states): To implement the call function of the\n",
        "LSTM cell, think about the different pathways and how the input\n",
        "and the different states are combined. 10\n",
        "\n",
        "2. Implement a LSTM layer, which is created from one (or multiple for\n",
        "a multi-layer LSTM) LSTM Cell. This LSTM layer should operate on\n",
        "inputs with multiple time steps.\n",
        "\n",
        "• init (self,cell): It is easier to start implementing single cell\n",
        "layers but you may think about ways to implement multi-layer LSTMs.\n",
        "\n",
        "• call(self, x, states) The call function takes the input over multiple time steps and creates (and returns!) the outputs over multiple\n",
        "time steps. The input is expected to be of shape [batch size, seq len,\n",
        "input size], the respective output of shape [batch size, seq len, output size] To achieve this you will have to ”unroll” the LSTM.\n",
        "To learn more about ”unrolling” if you are unsure what it means and\n",
        "want to know how to implement it efficiently, go to the subsection\n",
        "about Unrolling.\n",
        "\n",
        "• zero states(self, batch size): Define a function that, given a\n",
        "batch size, resets the states of the LSTM, thus returns a tuple of\n",
        "states of the appropriate size filled with zeros. 11\n",
        "\n",
        "3. Implement the final Model: This model should be a wrapper around\n",
        "your lstm implementation.\n",
        "\n",
        "• init (): You may want to use one or multiple read in layers and\n",
        "an output layer that takes the output of your LSTM and transforms\n",
        "it into your final prediction. 12\n",
        "\n",
        "• call(self,x): Here the input is over the whole sequence length.\n",
        "You should pass it through your read-in layers and then to your\n",
        "LSTM implementation 13 and finally to your read-out layer."
      ],
      "metadata": {
        "id": "pPSmQDE7MM5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sig_function = tf.keras.activations.sigmoid\n",
        "tan_function = tf.keras.activations.tanh\n",
        "\n",
        "class LSTM_Cell(tf.keras.Model): \n",
        "  def __init__(self, units): \n",
        "    super(LSTM_Cell, self).__init__()\n",
        "    self.units = units\n",
        "    self.forget_gate = tf.keras.layers.Dense(units, activation=sig_function, bias_initializer='ones')\n",
        "    self.input_gate = tf.keras.layers.Dense(units, activation=sig_function)\n",
        "    self.cell_state_candidates = tf.keras.layers.Dense(units, activation=tan_function)\n",
        "    self.output_gate = tf.keras.layers.Dense(units, activation=sig_function)\n",
        "\n",
        "  def call(self, x, states): \n",
        "    concat_inputs = tf.concat((x, states[0]), axis=1) # states is a tuple containing (hidden_state, cell_state). Axis 1 = seq_len\n",
        "\n",
        "    # applying the forget filter to the old cell state Ct−1 via point wise multiplication \n",
        "    ft = self.forget_gate(concat_inputs)\n",
        "    cell_state_update = ft * states[1] # states is a tuple containing (hidden_state, cell_state)\n",
        "\n",
        "    #do the same with our input filter and the candidate cell state C^t selecting new candidates.\n",
        "    it = self.input_gate(concat_inputs)\n",
        "    ct = self.cell_state_candidates(concat_inputs)\n",
        "    new_candidate = it * ct\n",
        "\n",
        "    #  We now combine that to form the new cell state Ct:\n",
        "    new_ct = tf.add(cell_state_update, new_candidate)\n",
        "\n",
        "    # Determining the hidden state/output\n",
        "    output = self.output_gate(concat_inputs)\n",
        "    new_hidden = output *tf.math.tanh(new_ct)\n",
        "\n",
        "    return new_ct, new_hidden\n",
        "\n",
        "\n",
        "class LSTM_Layer(tf.keras.Model): \n",
        "  def __init__(self, units=16): \n",
        "    super(LSTM_Layer, self).__init__()\n",
        "    self.cell = LSTM_Cell(units)\n",
        "\n",
        "  def call(self, x): \n",
        "    states = self.zero_states()\n",
        "    output_list = []\n",
        "    for index in range(x.shape[1]):\n",
        "      cell, hidden = self.cell(tf.squeeze(x[:,index,:]), states)\n",
        "      output_list = np.stack(hidden)\n",
        "      states = cell, hidden\n",
        "    print(output_list.shape)\n",
        "    return output_list\n",
        "\n",
        "  def zero_states(self, batch_size=32): \n",
        "    states = (np.zeros([batch_size, self.cell.units]), np.zeros([batch_size, self.cell.units])) # batch_size, cell plus hidden state and unit number??\n",
        "    return states\n",
        "\n",
        "\n",
        "class Final_Model(tf.keras.Model):\n",
        "  def __init__(self): \n",
        "    super(Final_Model, self).__init__()\n",
        "    self.input_layer = tf.keras.layers.Dense(units=16, activation='sigmoid')\n",
        "    self.lstm_layer = LSTM_Layer(units=16)\n",
        "    self.output_layer = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "    \n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.input_layer(x)\n",
        "    x = self.lstm_layer(x)\n",
        "    x = self.output_layer(x)\n",
        "    return x\n",
        "\n",
        "  \n",
        "'''    \n",
        "# idea of where this is going\n",
        "\n",
        "model = LSTM_Layer(units=16)\n",
        "\n",
        "model(inputs, states)\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "usU-hHE0ORwg",
        "outputId": "99500588-464a-4157-8a90-41bef63e2bed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'    \\n# idea of where this is going\\n\\nmodel = LSTM_Layer(units=16)\\n\\nmodel(inputs, states)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 Training\n",
        "Training mostly stays the same to any other binary classification task you have\n",
        "tackled so far. However, there is a key difference: You get a prediction on the\n",
        "level of several time steps, but for your loss and your accuracy, we only want to\n",
        "consider the prediction of the very last time step 14\n",
        "\n",
        ".\n",
        "Think of this task as a proof of concept task - getting some reasonable\n",
        "accuracy is really enough, no need to try and push it this week. So don’t feel\n",
        "pressured to use any sort of more advanced optimization.\n",
        "Be aware that training might take longer, especially if you decide not to\n",
        "make use of graph mode. It is enough if you can see a significant improvement\n",
        "in loss and accuracy after the second epoch of training, and it is very reasonable\n",
        "to get to at least 80% accuracy.\n"
      ],
      "metadata": {
        "id": "DSbQjG6h7755"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, input, target, loss_function, optimizer):\n",
        "  \"\"\"Applys optimizer to all trainable variables of this model to\n",
        "  minimize the loss (loss_function) between the target output and the\n",
        "  predicted ouptut.\n",
        "  :param input: tf.Tensor input to the model\n",
        "  :param target: target output with repect to the input\n",
        "  :return: the loss and the accuracy of the models prediction\n",
        "   \"\"\"\n",
        "  # loss_object and optimizer_object are instances of respective tensorflow classes\n",
        "  with tf.GradientTape() as tape:\n",
        "    prediction = model(input)\n",
        "    loss = loss_function(target, prediction)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "def test(model, test_data, loss_function):\n",
        "  \"\"\"Calculate the mean loss and accuracy of the model over all elements\n",
        "  of test_data.\n",
        "  :param test_data: model is evaulated for test_data\n",
        "  :param: loss_function: chosen cost function\n",
        "  :return: mean loss and mean accuracy for all datapoints\n",
        "  \"\"\"\n",
        "\n",
        "  # test over complete test data\n",
        "  test_accuracy_aggregator = []\n",
        "  test_loss_aggregator = []\n",
        "\n",
        "  for (input, target) in test_data:\n",
        "    prediction = model(input)\n",
        "    sample_test_loss = loss_function(target, prediction)\n",
        "    sample_test_accuracy =  np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
        "    sample_test_accuracy = np.mean(sample_test_accuracy)\n",
        "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
        "    test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
        "\n",
        "  test_loss = tf.reduce_mean(test_loss_aggregator)\n",
        "  test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
        "\n",
        "  return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "SAQelwDs_4tE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "### Hyperparameters\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Initialize the model.\n",
        "model = Final_Model()\n",
        "# Initialize the loss.\n",
        "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "# Initialize the optimizer.\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# Initialize lists for later visualization.\n",
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "\n",
        "#check how model performs on train data once before we begin\n",
        "loss, accuracy = test(model, dataset, cross_entropy_loss)\n",
        "losses.append(loss)\n",
        "accuracies.append(accuracy)\n",
        "\n",
        "# train for num_epochs epochs.\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch: {str(epoch)} starting with accuracy {accuracies[-1]}')\n",
        "    \n",
        "    #training (and checking in with training)\n",
        "    epoch_loss_agg = []\n",
        "    for input,target in dataset:\n",
        "        loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
        "        epoch_loss_agg.append(loss)\n",
        "    \n",
        "    #track training loss\n",
        "    losses.append(tf.reduce_mean(epoch_loss_agg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wsN3TnEX8AbA",
        "outputId": "15d90724-c81d-4a26-85d0-fb2a6776ea5d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n",
            "(32, 16)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bd25fcd55ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#check how model performs on train data once before we begin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-8cbee8bb2fb6>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_data, loss_function)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0msample_test_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0msample_test_accuracy\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1082\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1083\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-74de2db902fc>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1082\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1083\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-74de2db902fc>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m       \u001b[0moutput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m       \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0m_arrays_for_stack_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0m_arrays_for_stack_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   7217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7218\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7219\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7220\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7221\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m       \u001b[0;34m\"strided_slice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbegin\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m       skip_on_eager=False) as name:\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[0;34m(name, default_name, values, skip_on_eager)\u001b[0m\n\u001b[1;32m   6636\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6637\u001b[0m   \"\"\"\n\u001b[0;32m-> 6638\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6639\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minternal_name_scope_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecuting_eagerly\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2082\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_execution_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecuting_eagerly\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    903\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0;34m\"\"\"Returns True if current thread has eager executing enabled.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mones_rank_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}