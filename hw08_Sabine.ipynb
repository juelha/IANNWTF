{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw08_Sabine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCLZGRJAYNiOkvOgQsegbn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juelha/IANNWTF/blob/sabine/hw08_Sabine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcnVmUQUzs_4"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import tensorflow as tf \n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset and prepossing\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "shape_train = x_train.shape\n",
        "shape_test = x_test.shape\n",
        "\n",
        "x_train = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "x_test = tf.data.Dataset.from_tensor_slices(x_test)\n",
        "print(x_train)\n",
        "\n",
        "def preprocessing(tensor):\n",
        "  tensor = tensor.map(lambda images: (tf.cast(images, tf.float32) / 255.)) # normalise\n",
        "  tensor = tensor.map(lambda images: (tf.expand_dims(images, -1))) # make 3D in case\n",
        "  tensor = tensor.map(lambda images: (tf.add(images, tf.random.normal((28,28,1), mean=0, stddev=1)))) # add noise with random 28,28 matrix \n",
        "  tensor = tensor.map(lambda images: (tf.clip_by_value(images, clip_value_min=0, clip_value_max=1))) # keep values normalised by clipping\n",
        "  #tensor = tensor.map(lambda images: (tf.cast(images, tf.uint8)))\n",
        "  print(tensor)\n",
        "  tensor = tensor.shuffle(1000)\n",
        "  tensor = tensor.batch(32)\n",
        "  tensor = tensor.prefetch(20)\n",
        "  return tensor\n",
        "\n",
        "\n",
        "train_dataset = x_train.apply(preprocessing)\n",
        "test_dataset = x_test.apply(preprocessing)\n",
        "\n",
        "for image in train_dataset:\n",
        "  train_data = image\n",
        "  break\n",
        "\n",
        "print(train_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwysDsYB0mhl",
        "outputId": "8512c0bd-323a-4c0c-87bb-09168d413669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<TensorSliceDataset shapes: (28, 28), types: tf.uint8>\n",
            "<MapDataset shapes: (28, 28, 1), types: tf.float32>\n",
            "<MapDataset shapes: (28, 28, 1), types: tf.float32>\n",
            "(32, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.1 Convolutional Autoencoder\n",
        "\n",
        "• The Autoencoder should consist of an encoder and a decoder, which can\n",
        "be called independently. 6\n",
        "• Encoder: The encoder should reduce the size of feature maps like a CNN.78\n",
        "At the end of the encoder, flatten the feature maps and use a dense layer\n",
        "to produce an embedding of a certain size. 9\n",
        "• Decoder: The decoder takes the embedding from the encoder as input.\n",
        "Use a dense layer to restore the dimensionality of the flattened feature\n",
        "maps from the encoder and reshape the resulting vector into feature maps\n",
        "again. Use upsampling or transposed convolutions to mirror your encoder.\n",
        "As an output layer, use a convolutional layer with one filter and sigmoid\n",
        "activation to produce an output image.\n"
      ],
      "metadata": {
        "id": "TD9K0j8jsePs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model): \n",
        "  def __init__(self, latent_dim=10): \n",
        "    super(Encoder, self).__init__()\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(28, 28))\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.dense1 = tf.keras.layers.Dense(7*7*64, activation='relu') # LOOK HERE JAY: Use a dense layer to force a tensor shape that in the encoder that can be reshaped in the decoder!\n",
        "    self.dense2 = tf.keras.layers.Dense(latent_dim)\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, input):\n",
        "    x = self.conv1(input)\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.dense2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "5xlfTlRC2Rpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model): \n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dense = tf.keras.layers.Dense(7*7*64, activation='relu')\n",
        "    self.reshape = tf.keras.layers.Reshape((7,7,64))\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')\n",
        "    self.out = tf.keras.layers.Conv2D(filters=1, kernel_size=(3, 3), padding='same', activation='relu')\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, input): \n",
        "    x = self.dense(input)\n",
        "    x = self.reshape(x)\n",
        "    x = self.conv1(x)\n",
        "    x = self.out(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "hSetjJO1Yj5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(tf.keras.Model): \n",
        "  def __init__(self):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = Encoder()\n",
        "    self.decoder = Decoder()\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, input): \n",
        "    x = self.encoder(input)\n",
        "    x = self.decoder(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "UYgJsbpK4fIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Autoencoder()\n",
        "out = model(train_data)"
      ],
      "metadata": {
        "id": "QzfdQzlJ4Yef"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}