{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw08_Sabine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJltRzH8BIHHcGzQtWVvVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juelha/IANNWTF/blob/sabine/hw08_Sabine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pcnVmUQUzs_4"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import tensorflow as tf \n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset and prepossing\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "shape_train = x_train.shape\n",
        "shape_test = x_test.shape\n",
        "\n",
        "x_train = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "x_test = tf.data.Dataset.from_tensor_slices(x_test)\n",
        "print(x_train)\n",
        "\n",
        "def preprocessing(tensor):\n",
        "  tensor = tensor.map(lambda images: (tf.cast(images, tf.float32) / 255.)) # normalise\n",
        "  tensor = tensor.map(lambda images: (tf.expand_dims(images, -1))) # make 3D in case\n",
        "  tensor = tensor.map(lambda images: (tf.add(images, tf.random.normal((28,28,1), mean=0, stddev=1)))) # add noise with random 28,28 matrix \n",
        "  tensor = tensor.map(lambda images: (tf.clip_by_value(images, clip_value_min=0, clip_value_max=1))) # keep values normalised by clipping\n",
        "  #tensor = tensor.map(lambda images: (tf.cast(images, tf.uint8)))\n",
        "  print(tensor)\n",
        "  tensor = tensor.shuffle(1000)\n",
        "  tensor = tensor.batch(32)\n",
        "  tensor = tensor.prefetch(20)\n",
        "  return tensor\n",
        "\n",
        "\n",
        "train_dataset = x_train.apply(preprocessing)\n",
        "test_dataset = x_test.apply(preprocessing)\n",
        "\n",
        "print(train_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwysDsYB0mhl",
        "outputId": "36f7028e-1845-4e40-dcbb-d3362246c837"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "<TensorSliceDataset shapes: (28, 28), types: tf.uint8>\n",
            "<MapDataset shapes: (28, 28, 1), types: tf.float32>\n",
            "<MapDataset shapes: (28, 28, 1), types: tf.float32>\n",
            "<PrefetchDataset shapes: (None, 28, 28, 1), types: tf.float32>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.1 Convolutional Autoencoder\n",
        "\n",
        "• The Autoencoder should consist of an encoder and a decoder, which can\n",
        "be called independently. 6\n",
        "• Encoder: The encoder should reduce the size of feature maps like a CNN.78\n",
        "At the end of the encoder, flatten the feature maps and use a dense layer\n",
        "to produce an embedding of a certain size. 9\n",
        "• Decoder: The decoder takes the embedding from the encoder as input.\n",
        "Use a dense layer to restore the dimensionality of the flattened feature\n",
        "maps from the encoder and reshape the resulting vector into feature maps\n",
        "again. Use upsampling or transposed convolutions to mirror your encoder.\n",
        "As an output layer, use a convolutional layer with one filter and sigmoid\n",
        "activation to produce an output image.\n"
      ],
      "metadata": {
        "id": "TD9K0j8jsePs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model): \n",
        "  def __init__(self): \n",
        "    super(Encoder, self).__init__()\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(28, 28))\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.dense = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, input):\n",
        "    x = self.conv1(input)\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "5xlfTlRC2Rpu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Encoder()\n",
        "\n",
        "out = model(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "eA464ImM4h8p",
        "outputId": "5576e5a8-b466-46b8-c71e-7020794c6e39"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d91662377fde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"encoder\" (type Encoder).\n\nin user code:\n\n    File \"<ipython-input-3-71a4b1dc4b07>\", line 10, in call  *\n        x = self.conv1(input)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 196, in assert_input_compatibility\n        raise TypeError(f'Inputs to a layer should be tensors. Got: {x}')\n\n    TypeError: Inputs to a layer should be tensors. Got: <_VariantDataset shapes: (None, 28, 28, 1), types: tf.float32>\n\n\nCall arguments received:\n  • input=<PrefetchDataset shapes: (None, 28, 28, 1), types: tf.float32>"
          ]
        }
      ]
    }
  ]
}