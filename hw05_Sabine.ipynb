{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_05 Sabine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkzpa2NhE3cMAQBNUd35gF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juelha/IANNWTF/blob/sabine/Homework_05_Sabine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gupg-fyMjzr"
      },
      "source": [
        "# 1 Data set\n",
        "As CNNs are very fashionable, in this week we would like you to work with the Fashion\n",
        "MNIST Dataset.\n",
        "Note that this is very similar to the MNIST dataset that you have already seen in\n",
        "notebooks on courseware. The images have the same shape and there are the same\n",
        "number of classes.\n",
        "1.1 Construct a Data Pipeline\n",
        "Make yourself familiar with the dataset and construct a Data Pipeline. Perform all the\n",
        "preprocessing steps that you deem necessary. 12\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2O2OEXct8B8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "(train_images, train_labels),(test_images, test_labels) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# normalise pixel values \n",
        "train_images = train_images /  255.0\n",
        "test_images = test_images / 255.0\n",
        "validation_images = train_images[:5000]\n",
        "validation_labels = train_labels[:5000]\n",
        "\n",
        "assert train_images.shape == (60000, 28, 28)\n",
        "assert test_images.shape == (10000, 28, 28)\n",
        "assert train_labels.shape == (60000,)\n",
        "assert test_labels.shape == (10000,)\n",
        "\n",
        "#train_dataset = tf.concat([train_images, train_labels], 1)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "\n",
        "def preprocessing(tensor):\n",
        "  tensor = tensor.map(lambda images, labels: (tf.expand_dims(images, -1), tf.one_hot(labels, 10)))\n",
        "  #cache this progress in memory, as there is no need to redo it; it is deterministic after all\n",
        "  tensor = tensor.cache()\n",
        "  #shuffle, batch, prefetch\n",
        "  tensor = tensor.shuffle(1000)\n",
        "  tensor = tensor.batch(32)\n",
        "  tensor = tensor.prefetch(20)\n",
        "  #return preprocessed dataset\n",
        "  return tensor\n",
        "\n",
        "train_dataset = train_dataset.apply(preprocessing)\n",
        "test_dataset = test_dataset.apply(preprocessing)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7ZdbiwBMsoC"
      },
      "source": [
        "# 2 Model\n",
        "Although the basic procedure of defining a CNN Model is the same, you will need to\n",
        "use entirely different layers this week. We want you to experiment a bit with how to\n",
        "structure your CNN but here are some general hints:\n",
        "• You may want to alternate between convolutional layers and pooling layers. 3\n",
        "• Find the middle ground between the depth of the network and the number of filters\n",
        "used in each layer. Maybe consider the idea of the receptive field when deciding\n",
        "on the parameters. 4\n",
        "• Find the right parameters for the layers.5\n",
        "• As this is an image classification task, make sure to have a classifier architecture\n",
        "following your convolutional and pooling operations. 6\n",
        "\n",
        "A kernel size of 3, no stride and ’same’ padding usually is a good starting point. For filter sizes, we\n",
        "didn’t use more than 64 filters per layer, but feel free to experiment (be aware of lengthy training times\n",
        "though)\n",
        "\n",
        "Apply Global Average Pooling followed by a Dense layer with the number of units depending on\n",
        "your number of classes. Use a softmax activation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3VwMfTDmcff"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(28, 28))\n",
        "        self.maxpooling1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')\n",
        "        self.maxpooling2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')\n",
        "        #flatten layer global average or max pooling\n",
        "        self.flatten = tf.keras.layers.GlobalMaxPooling2D()\n",
        "        self.dense1 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.maxpooling1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpooling2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        return x\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbpKXtTa1wVo"
      },
      "source": [
        "# Receptive Field Size \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADFcsOgYRV-H"
      },
      "source": [
        "# 3 Training \n",
        "\n",
        "Start by training your network for 10 epochs using a learning rate of 0.1. You can\n",
        "again copy most of the training procedure from previous scripts. 7 You may use all the\n",
        "optimization and regularization techniques that you wish and find applicable.\n",
        "To pass this task, achieve at least an accuracy of 85% on the test dataset. 8\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGM4S2RHp4zB"
      },
      "source": [
        "def train_step(model, input, target, loss_function, optimizer):\n",
        "  # loss_object and optimizer_object are instances of respective tensorflow classes\n",
        "  with tf.GradientTape() as tape:\n",
        "    prediction = model(input)\n",
        "    loss = loss_function(target, prediction)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "def test(model, test_data, loss_function):\n",
        "  # test over complete test data\n",
        "\n",
        "  test_accuracy_aggregator = []\n",
        "  test_loss_aggregator = []\n",
        "\n",
        "  for (input, target) in test_data:\n",
        "    prediction = model(input)\n",
        "    sample_test_loss = loss_function(target, prediction)\n",
        "    sample_test_accuracy =  np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
        "    sample_test_accuracy = np.mean(sample_test_accuracy)\n",
        "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
        "    test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
        "\n",
        "  test_loss = tf.reduce_mean(test_loss_aggregator)\n",
        "  test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
        "\n",
        "  return test_loss, test_accuracy"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2bk6joDrLFX",
        "outputId": "bed79fc9-dfac-4763-d997-4a216eafa2f7"
      },
      "source": [
        "# Put everything together\n",
        "\n",
        "'''\n",
        "Then train your network for 10 epochs using a learning rate of 0.1. As a loss use the\n",
        "categorical cross entropy. As an optimizer use SGD.\n",
        "'''\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#For showcasing we only use a subset of the training and test data (generally use all of the available data!)\n",
        "#train_dataset = train_dataset.take(1000)\n",
        "#test_dataset = test_dataset.take(100)\n",
        "\n",
        "### Hyperparameters\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Initialize the model.\n",
        "model = MyModel()\n",
        "# Initialize the loss.\n",
        "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "# Initialize the optimizer.\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# Initialize lists for later visualization.\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "#testing once before we begin\n",
        "test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
        "test_losses.append(test_loss)\n",
        "test_accuracies.append(test_accuracy)\n",
        "\n",
        "#check how model performs on train data once before we begin\n",
        "train_loss, train_accuracy = test(model, train_dataset, cross_entropy_loss)\n",
        "train_losses.append(train_loss)\n",
        "train_accuracies.append(train_accuracy)\n",
        "\n",
        "\n",
        "# We train for num_epochs epochs.\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch: {str(epoch)} starting with accuracy {test_accuracies[-1]}')\n",
        "    \n",
        "    #training (and checking in with training)\n",
        "    epoch_loss_agg = []\n",
        "    for input,target in train_dataset:\n",
        "        train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
        "        epoch_loss_agg.append(train_loss)\n",
        "    \n",
        "    #track training loss\n",
        "    train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
        "\n",
        "    #testing, so we can track accuracy and test loss\n",
        "    test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    print(f'Train Losses: {train_loss}, Test Losses: {test_loss}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 starting with accuracy 0.0994408945686901\n",
            "Train Losses: 0.2571730315685272, Test Losses: 0.38099825382232666\n",
            "Epoch: 1 starting with accuracy 0.8616214057507987\n",
            "Train Losses: 0.2558862864971161, Test Losses: 0.33777713775634766\n",
            "Epoch: 2 starting with accuracy 0.87689696485623\n",
            "Train Losses: 0.11835536360740662, Test Losses: 0.3318798542022705\n",
            "Epoch: 3 starting with accuracy 0.8782947284345048\n",
            "Train Losses: 0.3854769170284271, Test Losses: 0.2863708436489105\n",
            "Epoch: 4 starting with accuracy 0.8962659744408946\n",
            "Train Losses: 0.15222887694835663, Test Losses: 0.28284886479377747\n",
            "Epoch: 5 starting with accuracy 0.900758785942492\n",
            "Train Losses: 0.10465922951698303, Test Losses: 0.2784772217273712\n",
            "Epoch: 6 starting with accuracy 0.9022563897763578\n",
            "Train Losses: 0.15338842570781708, Test Losses: 0.25975656509399414\n",
            "Epoch: 7 starting with accuracy 0.9072484025559105\n",
            "Train Losses: 0.06908796727657318, Test Losses: 0.26980772614479065\n",
            "Epoch: 8 starting with accuracy 0.9035543130990416\n",
            "Train Losses: 0.16289660334587097, Test Losses: 0.2618984878063202\n",
            "Epoch: 9 starting with accuracy 0.9072484025559105\n",
            "Train Losses: 0.06696196645498276, Test Losses: 0.24970491230487823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZnQ8A-b2LO5"
      },
      "source": [
        "# Receptive Field Size \n",
        "Compute the receptive field size of the final layer of your convolutional Neural\n",
        "Network. Provide step by step computations with explanations to follow what and\n",
        "why you are doing these computational steps. Does your receptive field size cover\n",
        "the whole input region / a sufficiently large enough region of the input to perform\n",
        "the task? In doubt, incorporate your findings to adjust your network architecture\n",
        "to boost up the accuracy.\n",
        "\n",
        "• Optional: As later you will have to deal with more complex architectures to actually analytically compute the receptive field size, you may want to try and automatize the process. Feel free to come up with your own algorithm / way of doing so\n",
        "or for example make use of this library.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gckk4l2H5Zm9"
      },
      "source": [
        " def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(28, 28))\n",
        "        self.maxpooling1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')\n",
        "        self.maxpooling2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')\n",
        "        #flatten layer global average or max pooling\n",
        "        self.flatten = tf.keras.layers.GlobalMaxPooling2D()\n",
        "        self.dense1 = tf.keras.layers.Dense(10, activation='softmax'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8741BxJ14OY",
        "outputId": "2e64362c-1d80-459a-fb4a-884a8e101524"
      },
      "source": [
        "\n",
        "#Compute input size that leads to a 1x1 output size, among other things   \n",
        "# [filter size, stride, padding]\n",
        "\n",
        "conv_net = {\n",
        "    'conv1': [3,1,1],\n",
        "    'pool1': [2,1,0],\n",
        "    'conv2': [3,1,1],\n",
        "    'pool2': [2,1,0],\n",
        "    'conv3': [3,1,1],\n",
        "    'dense1': [1,1,0]\n",
        "}\n",
        "\n",
        "class ReceptiveFieldCalculator():\n",
        "    def calculate(self, architecture, input_image_size):\n",
        "        input_layer = ('input_layer', input_image_size, 3, 1, 1.5)\n",
        "        self._print_layer_info(input_layer)\n",
        "        \n",
        "        for key in architecture:\n",
        "            current_layer = self._calculate_layer_info(architecture[key], input_layer, key)\n",
        "            self._print_layer_info(current_layer)\n",
        "            input_layer = current_layer\n",
        "            \n",
        "    def _print_layer_info(self, layer):\n",
        "        print(f'------')\n",
        "        print(f'{layer[0]}: n = {layer[1]}; r = {layer[2]}; j = {layer[3]}; start = {layer[4]}')     \n",
        "        print(f'------')\n",
        "            \n",
        "    def _calculate_layer_info(self, current_layer, input_layer, layer_name):\n",
        "        n_in = input_layer[1]\n",
        "        j_in = input_layer[2]\n",
        "        r_in = input_layer[3]\n",
        "        start_in = input_layer[4]\n",
        "        \n",
        "        k = current_layer[0]\n",
        "        s = current_layer[1]\n",
        "        p = current_layer[2]\n",
        "\n",
        "        n_out = math.floor((n_in - k + 2*p)/s) + 1\n",
        "        padding = (n_out-1)*s - n_in + k \n",
        "        p_right = math.ceil(padding/2)\n",
        "        p_left = math.floor(padding/2)\n",
        "\n",
        "        j_out = j_in * s\n",
        "        r_out = r_in + (k - 1)*j_in\n",
        "        start_out = start_in + ((k-1)/2 - p_left)*j_in\n",
        "        return layer_name, n_out, j_out, r_out, start_out\n",
        "\n",
        "calculator = ReceptiveFieldCalculator()\n",
        "calculator.calculate(conv_net, 28)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "input_layer: n = 28; r = 3; j = 1; start = 1.5\n",
            "------\n",
            "------\n",
            "conv1: n = 28; r = 3; j = 7; start = 1.5\n",
            "------\n",
            "------\n",
            "pool1: n = 27; r = 3; j = 10; start = 3.0\n",
            "------\n",
            "------\n",
            "conv2: n = 27; r = 3; j = 16; start = 3.0\n",
            "------\n",
            "------\n",
            "pool2: n = 26; r = 3; j = 19; start = 4.5\n",
            "------\n",
            "------\n",
            "conv3: n = 26; r = 3; j = 25; start = 4.5\n",
            "------\n",
            "------\n",
            "dense1: n = 26; r = 3; j = 25; start = 4.5\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL_AnsvZMgR3"
      },
      "source": [
        "#4 Visualization\n",
        "Visualize accuracy and loss for training and test data using matplotlib.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLD9tS2ZO_3u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "eb8fc39c-1754-4fcd-d403-ee07691a2ad2"
      },
      "source": [
        "# Visualisations\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize accuracy and loss for training and test data.\n",
        "plt.figure()\n",
        "line1, = plt.plot(train_losses)\n",
        "line2, = plt.plot(test_losses)\n",
        "line3, = plt.plot(test_accuracies)\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend((line1,line2, line3),(\"training losses\",\"test losses\", \"test accuracy\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SLRNUuOXkp1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5f65eba5-60f5-456b-b9be-64d0b7d513a5"
      },
      "source": [
        "'''\n",
        "Baselines: \n",
        "Epoch 1/10\n",
        "1875/1875 [==============================] - 25s 8ms/step - loss: 0.4923 - accuracy: 0.8175 - val_loss: 0.3930 - val_accuracy: 0.8581\n",
        "Epoch 2/10\n",
        "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3233 - accuracy: 0.8822 - val_loss: 0.3101 - val_accuracy: 0.8890\n",
        "Epoch 3/10\n",
        "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2773 - accuracy: 0.8984 - val_loss: 0.3073 - val_accuracy: 0.8878\n",
        "Epoch 4/10\n",
        "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2472 - accuracy: 0.9084 - val_loss: 0.2738 - val_accuracy: 0.8996\n",
        "Epoch 5/10\n",
        "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2271 - accuracy: 0.9158 - val_loss: 0.2704 - val_accuracy: 0.9029\n",
        "Epoch 6/10\n",
        "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2034 - accuracy: 0.9240 - val_loss: 0.2629 - val_accuracy: 0.9026\n",
        "Epoch 7/10\n",
        "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1861 - accuracy: 0.9309 - val_loss: 0.2653 - val_accuracy: 0.9041\n",
        "Epoch 8/10\n",
        "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1698 - accuracy: 0.9368 - val_loss: 0.2725 - val_accuracy: 0.9077\n",
        "Epoch 9/10\n",
        "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1565 - accuracy: 0.9411 - val_loss: 0.2815 - val_accuracy: 0.9086\n",
        "Epoch 10/10\n",
        "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1435 - accuracy: 0.9459 - val_loss: 0.2812 - val_accuracy: 0.9108\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "# receptive field code \n",
        "\n",
        "from receptivefield.image import get_default_image\n",
        "from receptivefield.keras import KerasReceptiveField\n",
        "\n",
        "# define model function\n",
        "def model_build_func(input_shape):\n",
        "    act = 'linear' # see Remarks\n",
        "    inp = Input(shape=input_shape, name='input_image')\n",
        "    x = Conv2D(32, (7, 7), activation=act)(inp)\n",
        "    x = Conv2D(32, (5, 5), activation=act)(x)\n",
        "    x = AvgPool2D()(x)\n",
        "    x = Conv2D(64, (5, 5), activation=act, name='feature_grid')(x)\n",
        "    x = AvgPool2D()(x)\n",
        "    model = Model(inp, x)\n",
        "    return model\n",
        "\n",
        "shape = [64, 64, 3]\n",
        "# compute receptive field\n",
        "rf = KerasReceptiveField(model_build_func, init_weights=True)\n",
        "rf_params = rf.compute(shape, 'input_image', ['feature_grid'])\n",
        "# debug receptive field\n",
        "rf.plot_rf_grids(get_default_image(shape, name='doge'))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# receptive field code \\n\\nfrom receptivefield.image import get_default_image\\nfrom receptivefield.keras import KerasReceptiveField\\n\\n# define model function\\ndef model_build_func(input_shape):\\n    act = 'linear' # see Remarks\\n    inp = Input(shape=input_shape, name='input_image')\\n    x = Conv2D(32, (7, 7), activation=act)(inp)\\n    x = Conv2D(32, (5, 5), activation=act)(x)\\n    x = AvgPool2D()(x)\\n    x = Conv2D(64, (5, 5), activation=act, name='feature_grid')(x)\\n    x = AvgPool2D()(x)\\n    model = Model(inp, x)\\n    return model\\n\\nshape = [64, 64, 3]\\n# compute receptive field\\nrf = KerasReceptiveField(model_build_func, init_weights=True)\\nrf_params = rf.compute(shape, 'input_image', ['feature_grid'])\\n# debug receptive field\\nrf.plot_rf_grids(get_default_image(shape, name='doge'))\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}