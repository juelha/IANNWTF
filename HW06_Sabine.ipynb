{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW06_Sabine.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMU9+PyYJmfsYjvL7fsWjda",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juelha/IANNWTF/blob/sabine/HW06_Sabine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loKnj46fR7WH"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WLX1r2pRKof"
      },
      "source": [
        "#1 Data set\n",
        "We will work with the Tensorflow Cifar10 dataset. https://www.cs.toronto.edu%7Ekriz/cifar.html. It contains 60.000 coloured images of cells with equal sizes. Each\n",
        "image corresponds to one of 10 categories. The dataset is already implemented as a\n",
        "keras.dataset module and very convenient to load!\n",
        "Perform necessary or beneficial preprocessing steps.1 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tofmhSNWRJOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d724e700-22f2-487b-9f69-f067ae81ba88"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "assert train_images.shape == (50000, 32, 32, 3)\n",
        "assert test_images.shape == (10000, 32, 32, 3)\n",
        "assert train_labels.shape == (50000, 1)\n",
        "assert test_labels.shape == (10000, 1)\n",
        "\n",
        "# TO DO: use min-max feature here or z scores \n",
        "train_images = train_images /  255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "\n",
        "#print(train_dataset.take(1))\n",
        "\n",
        "def preprocessing(tensor):\n",
        "  \"\"\" apply a preprocessing pipeline to the given dataset\n",
        "  :param tensor: data to be preprocessed\n",
        "  :return: preprocessed dataset\n",
        "  \"\"\"\n",
        "  # map the labels to one_hot labels and expand the last dimension of the images \n",
        "  tensor = tensor.map(lambda images, labels: (images, tf.one_hot(labels, 10)))\n",
        "  #print(tensor.take(1))\n",
        "  # cache this progress in memory\n",
        "  tensor = tensor.cache()\n",
        "  # shuffle, batch, prefetch\n",
        "  tensor = tensor.shuffle(1000)\n",
        "  tensor = tensor.batch(64)\n",
        "  tensor = tensor.prefetch(20)\n",
        "  # return preprocessed dataset\n",
        "  return tensor\n",
        "\n",
        "# apply the preprocessing pipeline to both the training and the test dataset\n",
        "train_dataset = train_dataset.apply(preprocessing)\n",
        "test_dataset = test_dataset.apply(preprocessing)\n",
        "\n",
        "for image, label in train_dataset: \n",
        "  image_shape = list(image.shape[1:])\n",
        "  image_shape.insert(0, 1)\n",
        "  break\n",
        "\n",
        "print(image_shape)\n"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 32, 32, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75zyljE_U1fj"
      },
      "source": [
        "## 2.1 ResNet\n",
        "• Start with implementing a callable ResidualBlock class. 3\n",
        "Implement an init function defining the main building blocks: Your residual\n",
        "block should consist of multiple alterations of Convolution and Batch Normalization layers. You will need to make sure that the output of the block has the same\n",
        "dimensions as its input. 4\n",
        "\n",
        "Implement a call function. 5\n",
        "\n",
        "• Implement a callable ResNet class, consisting of a convolutional layer followed by\n",
        "multiple Residual Blocks and an output layer. 6\n",
        "To further explore your networks behaviour, it might be convenient to implement\n",
        "it in a way that you can easily alter the number of Residual Blocks. 7\n",
        "Implement the network’s call function. 8\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyqUdBQ77DFr"
      },
      "source": [
        "# Custom ResidualBlock Model\n",
        "class ResidualBlock(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, mode = \"normal\", input_shape = (32,32,3), out_filters = 64):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.batch_normal = tf.keras.layers.BatchNormalization()\n",
        "        self.activation = tf.keras.layers.Activation(tf.nn.relu)\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\")\n",
        "\n",
        "        self.list_layers = []\n",
        "        self.transform_original = []\n",
        "\n",
        "        if mode == \"normal\":\n",
        "          self.list_layers.append(tf.keras.layers.Conv2D(filters=out_filters/2, kernel_size =(3,3), padding=\"same\"))\n",
        "          self.list_layers.append(tf.keras.layers.Conv2D(filters=out_filters, kernel_size =(3,3), padding=\"same\"))\n",
        "\n",
        "          # transform original input to also have 256 channels\n",
        "          self.transform_original.append(tf.keras.layers.Conv2D(filters=out_filters, kernel_size=(1,1)))\n",
        "    \n",
        "        # some blocks in ResNetV2 have a MaxPool with 1x1 pool size and strides of 2 instead\n",
        "        elif mode == \"strided\":\n",
        "           \n",
        "            # do strided convolution (reducing feature map size)\n",
        "            self.list_layers.append(tf.keras.layers.Conv2D(filters=out_filters/2, kernel_size =(3,3), padding=\"same\"))\n",
        "            self.list_layers.append(tf.keras.layers.Conv2D(filters=out_filters, kernel_size =(3,3), padding=\"same\", strides=(2,2)))\n",
        "\n",
        "            # transform original input with 1x1 strided max pooling to match output shape\n",
        "            self.transform_original.append(tf.keras.layers.Conv2D(filters=out_filters, kernel_size=(1,1)))\n",
        "            self.transform_original.append(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "            \n",
        "        # other ResNetV2 blocks keep both the size and channel number constant\n",
        "        elif mode == \"constant\":\n",
        "            self.list_layers.append(tf.keras.layers.Conv2D(filters=out_filters, kernel_size =(3,3), padding=\"same\"))\n",
        "            self.transform_original.append(tf.keras.layers.Conv2D(filters=out_filters, kernel_size =(1,1), kernel_initializer=\"Ones\", padding=\"same\", trainable = False ))\n",
        "\n",
        "\n",
        "    def call(self, x_in):\n",
        "\n",
        "        # have an initial Conv layer before the first res block (increasing the n of channels)\n",
        "        x = self.conv1(x_in) \n",
        "        x_out = x\n",
        "        for layer in self.list_layers:\n",
        "          x_out = layer(x_out)\n",
        "\n",
        "        for layer in self.transform_original:\n",
        "          x = layer(x)\n",
        "          print(x_out.shape)\n",
        "\n",
        "        x_out = self.batch_normal(x_out)\n",
        "        x_out = self.activation(x_out)\n",
        "\n",
        "        x_out = tf.keras.layers.Add()([x_out, x])\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class MyModel(tf.keras.Model): \n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "\n",
        "    self.block1 = ResidualBlock(mode = 'strided', input_shape = image_shape)\n",
        "    self.block2 = ResidualBlock(mode = 'normal', input_shape = image_shape)\n",
        "  \n",
        "  def call(self, x):\n",
        "    x_out = self.block1(x)\n",
        "    x_out = self.block2(x_out)\n",
        "\n",
        "    return x_out \n",
        "\n"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsZhU46kqZEI",
        "outputId": "79d9d40e-deec-40fe-a40e-f800db28ab2f"
      },
      "source": [
        "#image_shape = (1, 32,32,3)\n",
        "dummy = tf.ones(image_shape)\n",
        "\n",
        "#resblock_try = ResidualBlock(mode = 'strided', input_shape = (32,32,3))\n",
        "#out = resblock_try(dummy)\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "output = model(dummy)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 16, 16, 64)\n",
            "(1, 16, 16, 64)\n",
            "(1, 16, 16, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnCjV3bzW3o0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v8SGfoj-wI9"
      },
      "source": [
        "## 2.2 DenseNet\n",
        "• Start with the Implementation of a callable class for your Transition Layers.\n",
        "9\n",
        "• Implement the Dense Block class. Remember, a Dense Block is a series of convolutions where the original input is concatenated with the output of the convolution\n",
        "operation. 10 You may want to implement a subclass Block containing the convolution layer 11 and the concatenation implemented in the call function.\n",
        "Implement your Dense Block class in a way that you can easily alter the number\n",
        "of Dense Blocks you want to use. 12\n",
        "\n",
        "• Implement the DenseNet class.\n",
        "– You will want to have a set of layers before your Dense Blocks fixing the\n",
        "desired channel dimension you need to pass on to the Dense Blocks.\n",
        "– You will want to consecutively alter Dense Blocks and Transition Layers. 13\n",
        "14 Remember the use of the growth rate when creating the Transition Layer\n",
        "instances. 15\n",
        "– After the last Dense Block make sure to include a proper set of output layers.\n",
        "16\n",
        "Implement the respective call function. 17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3sQF8qR_AvQ"
      },
      "source": [
        "class TransitionLayer():\n",
        "\n",
        "  def __init__(self, input_shape):\n",
        "    self.batch_normal = tf.keras.layers.BatchNormalization(epsilon=1.001e-05)\n",
        "    self.activation = tf.keras.layers.Activation(tf.nn.relu)\n",
        "  \n",
        "    self.conv = tf.keras.layers.Conv2D(filters = reduce_filters_to, kernel_size=(1,1), padding=\"valid\", use_bias=False)\n",
        "\n",
        "    # bottleneck, reducing the number of feature maps\n",
        "    #(floor divide current number of filters by two for the bottleneck)\n",
        "    self.bottleneck = input_shape//2\n",
        "    # reduce the height and width of the feature map (not too useful for low-res input)\n",
        "    \n",
        "    self.pool = tf.keras.layers.AvgPool2D(pool_size=(2,2), strides = (2,2), padding = 'valid')\n",
        "  \n",
        "  def call(self, x):\n",
        "    x = self.batch_normal(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.conv(x)\n",
        "    x = self.bottleneck(x)\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb1GKhUsDY07"
      },
      "source": [
        "class DenseBlock(): \n",
        "\n",
        "  def __init__(self): \n",
        "    super(DenseBlock, self).__init__()\n",
        "    self.batch_normal =  tf.keras.layers.BatchNormalization(epsilon=1.001e-05)\n",
        "    self.activation = tf.keras.layers.Activation(tf.nn.relu)\n",
        "    \n",
        "    # 1x1 convolution with 128 filters (padding \"valid\" because with 1x1 we don't need padding)\n",
        "    self.conv1 = tf.keras.layers.Conv2D(n_filters, kernel_size=(1,1), padding=\"valid\", use_bias=False)\n",
        "    # 3x3 convolution with 32 filters (to be concatenated with the input)\n",
        "    self.conv2 = tf.keras.layers.Conv2D(new_channels, kernel_size=(3,3), padding=\"same\", use_bias=False)\n",
        "\n",
        "  \n",
        "  def block(self, x):\n",
        "    x_out = self.batch_normal(x) \n",
        "    x_out = self.activation(x_out)\n",
        "    x_out = self.conv1(x_out)\n",
        "    x_out = self.batch_normal(x_out)\n",
        "    x_out = self.activation(x_out)\n",
        "    x_out = self.conv2(x_out)\n",
        "    return x_out\n",
        "  \n",
        "  def call(self, x):\n",
        "    # Concatenate layer (just a tf.keras.layers.Layer that calls tf.concat)\n",
        "    x_out = tf.keras.layers.Concatenate(axis=3)([x, block(x)]) # axis 3 for channel dimension\n",
        "    return x_out\n",
        "\n",
        "\n",
        "# Custom Layer\n",
        "class DenseNet(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units=8):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.units = units\n",
        "        self.activation = tf.nn.softmax\n",
        "\n",
        "    def build(self, input_shape): \n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                               initializer='random_normal',\n",
        "                               trainable=True)\n",
        "        self.b = self.add_weight(shape=(self.units,),\n",
        "                               initializer='random_normal',\n",
        "                               trainable=True)\n",
        "\n",
        "    def call(self, inputs): \n",
        "        x = tf.matmul(inputs, self.w) + self.b\n",
        "        x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": 65,
      "outputs": []
    }
  ]
}